{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYBiW9Wwc2K7",
        "outputId": "703cba7c-5d3d-498f-ef25-713971a12e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# updating from 0.20/21 version to 1.0\n",
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mwk5v1TnRMUI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsqC_gTs439C"
      },
      "source": [
        "#### 1.\tLoad dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "0LDKIzCQSNLo",
        "outputId": "5864a654-c9b0-42d1-dba8-98719cc91932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
              "0       90       NaN   77053       HS-grad              9             Widowed   \n",
              "1       82   Private  132870       HS-grad              9             Widowed   \n",
              "2       66       NaN  186061  Some-college             10             Widowed   \n",
              "3       54   Private  140359       7th-8th              4            Divorced   \n",
              "4       41   Private  264663  Some-college             10           Separated   \n",
              "...    ...       ...     ...           ...            ...                 ...   \n",
              "32556   22   Private  310152  Some-college             10       Never-married   \n",
              "32557   27   Private  257302    Assoc-acdm             12  Married-civ-spouse   \n",
              "32558   40   Private  154374       HS-grad              9  Married-civ-spouse   \n",
              "32559   58   Private  151910       HS-grad              9             Widowed   \n",
              "32560   22   Private  201490       HS-grad              9       Never-married   \n",
              "\n",
              "              occupation   relationship   race     sex  capital.gain  \\\n",
              "0                    NaN  Not-in-family  White  Female             0   \n",
              "1        Exec-managerial  Not-in-family  White  Female             0   \n",
              "2                    NaN      Unmarried  Black  Female             0   \n",
              "3      Machine-op-inspct      Unmarried  White  Female             0   \n",
              "4         Prof-specialty      Own-child  White  Female             0   \n",
              "...                  ...            ...    ...     ...           ...   \n",
              "32556    Protective-serv  Not-in-family  White    Male             0   \n",
              "32557       Tech-support           Wife  White  Female             0   \n",
              "32558  Machine-op-inspct        Husband  White    Male             0   \n",
              "32559       Adm-clerical      Unmarried  White  Female             0   \n",
              "32560       Adm-clerical      Own-child  White    Male             0   \n",
              "\n",
              "       capital.loss  hours.per.week native.country income  \n",
              "0              4356              40  United-States  <=50K  \n",
              "1              4356              18  United-States  <=50K  \n",
              "2              4356              40  United-States  <=50K  \n",
              "3              3900              40  United-States  <=50K  \n",
              "4              3900              40  United-States  <=50K  \n",
              "...             ...             ...            ...    ...  \n",
              "32556             0              40  United-States  <=50K  \n",
              "32557             0              38  United-States  <=50K  \n",
              "32558             0              40  United-States   >50K  \n",
              "32559             0              40  United-States  <=50K  \n",
              "32560             0              20  United-States  <=50K  \n",
              "\n",
              "[32561 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-027bc328-c13a-4bd4-ae53-dd4282adb74e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education.num</th>\n",
              "      <th>marital.status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital.gain</th>\n",
              "      <th>capital.loss</th>\n",
              "      <th>hours.per.week</th>\n",
              "      <th>native.country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>77053</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>82</td>\n",
              "      <td>Private</td>\n",
              "      <td>132870</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>18</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66</td>\n",
              "      <td>NaN</td>\n",
              "      <td>186061</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>4356</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54</td>\n",
              "      <td>Private</td>\n",
              "      <td>140359</td>\n",
              "      <td>7th-8th</td>\n",
              "      <td>4</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>3900</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>Private</td>\n",
              "      <td>264663</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Separated</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>3900</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>310152</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>257302</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>40</td>\n",
              "      <td>Private</td>\n",
              "      <td>154374</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>58</td>\n",
              "      <td>Private</td>\n",
              "      <td>151910</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>22</td>\n",
              "      <td>Private</td>\n",
              "      <td>201490</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-027bc328-c13a-4bd4-ae53-dd4282adb74e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-027bc328-c13a-4bd4-ae53-dd4282adb74e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-027bc328-c13a-4bd4-ae53-dd4282adb74e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# download dataset from given link and rename adult.csv to 1994_census_income.csv\n",
        "# https://www.kaggle.com/datasets/uciml/adult-census-income\n",
        "data=pd.read_csv('/content/1994_census_income.csv',na_values='?')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85V08SxpT2R2",
        "outputId": "0f0c3cd0-5c7f-4d3e-fc9f-649f687f78ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (32561, 15)\n"
          ]
        }
      ],
      "source": [
        "print('Shape: ',data.shape)\n",
        "#Dataset comprises of 32561 observations and 15 characteristics (14 independant and 1 dependant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ai5I5rBUe9g",
        "outputId": "0e52900a-79c1-4c9d-cb8b-dbae4cb68976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             32561 non-null  int64 \n",
            " 1   workclass       30725 non-null  object\n",
            " 2   fnlwgt          32561 non-null  int64 \n",
            " 3   education       32561 non-null  object\n",
            " 4   education.num   32561 non-null  int64 \n",
            " 5   marital.status  32561 non-null  object\n",
            " 6   occupation      30718 non-null  object\n",
            " 7   relationship    32561 non-null  object\n",
            " 8   race            32561 non-null  object\n",
            " 9   sex             32561 non-null  object\n",
            " 10  capital.gain    32561 non-null  int64 \n",
            " 11  capital.loss    32561 non-null  int64 \n",
            " 12  hours.per.week  32561 non-null  int64 \n",
            " 13  native.country  31978 non-null  object\n",
            " 14  income          32561 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()\n",
        "# Data has 6 columns of int dtype, 9 of object(string) dtype\n",
        "# 'workclass','education_num','occupation','race','gender','native_country' columns have null/missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu8ZKzSpFC4Z"
      },
      "source": [
        "#### 2.\tData Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aS17qKcFr-U"
      },
      "source": [
        "##### Impute the missing values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YFwoUqBDX5ze"
      },
      "outputs": [],
      "source": [
        "# Impute the missing values present in categorical columns and numerical columns\n",
        "# Imputing missing values using most_frequent strategy\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\n",
        "data = pd.DataFrame(imp.fit_transform(data),columns=data.columns)\n",
        "\n",
        "data['education.num'] = data['education.num'].astype(pd.Int64Dtype(),errors='ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2loPhmzXFIrv"
      },
      "source": [
        "##### Encode target column and other categorical features \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iNuAGhvIZ86f"
      },
      "outputs": [],
      "source": [
        "# function to label encode given column in given dataset\n",
        "def le(data,i):\n",
        "  from sklearn.preprocessing import LabelEncoder \n",
        "  # label encode given column\n",
        "  data[i] = pd.DataFrame(LabelEncoder().fit_transform(data[i]),columns=[i])\n",
        "  return data\n",
        "\n",
        "# function to one hot encode given column in given dataset\n",
        "def ohe(data,i):\n",
        "  import pandas as pd\n",
        "  # store one hot encoded columns in temp\n",
        "  temp = pd.get_dummies(data[i],prefix=i)\n",
        "  # store index of given column in t\n",
        "  t = data.columns.get_loc(i)\n",
        "  # drop given column \n",
        "  data = data.drop(labels=i,axis=1)\n",
        "  # insert one hot encoded columns in index of the given column\n",
        "  for i in range(temp.shape[1]-1,-1,-1):\n",
        "    data.insert(t, temp.columns[i], temp.iloc[:,i],False)\n",
        "  return data\n",
        "  \n",
        "# Encode target column “high_income” : {encode values “<=50K” as 0 and “>50K” as 1} \n",
        "# the string '<=50' alphabetically comes before '>50' therefore Label encoding the target column gives us the desired effect\n",
        "data=le(data,data.columns[-1])\n",
        "\n",
        "# Encode the other categorical features \n",
        "# set limit\n",
        "lim=10 # if unique values in column are more than limit, then label encode them, else one hot encode them \n",
        "# iterate through all the columns in data\n",
        "for i in data.columns:\n",
        "  # if column values are not numeric\n",
        "  if type(data[i][0]) not in (np.int64,np.float64):\n",
        "    # if unique values in column are more than limit then label encode the column\n",
        "    if len(set(data[i]))>lim: data=le(data,i)\n",
        "###      # le_names.append(i) # append all column names which got label encoded\n",
        "    # if unique values in column are less than equal to 5 one hot encode the column\n",
        "    else: data=ohe(data,i)\n",
        "###      # ohe_names.append(i) # append all column names which got one hot encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBAT8yTQF9fr"
      },
      "source": [
        "##### Remove any undesirable feature from the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JwEz4HOfwuOo"
      },
      "outputs": [],
      "source": [
        "# splitting features and target variable\n",
        "X = data.iloc[:,:-1]\n",
        "y = data.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "202FT5GRXwRt"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "#apply SelectKBest class to extract top 15 best features using ANOVA f-score to evaluate\n",
        "X = pd.DataFrame(SelectKBest(k=15).fit_transform(X,y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kzBIbyC52gW"
      },
      "source": [
        "##### Check for the outliers in the columns and treat the outliers if present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OXTtgd8icYJI"
      },
      "outputs": [],
      "source": [
        "eps=1e-7\n",
        "# do log transformation of columns with outliers till there are no outliers left (should run max twice)\n",
        "while 1:\n",
        "  # checking outliers by using skewness from normal distribution\n",
        "  o_col=[]\n",
        "  skew = X.skew()\n",
        "  for c in X.columns:\n",
        "    if abs(skew[c])>1:\n",
        "      o_col.append(c)\n",
        "  # end the loop if there are no columns with outliers\n",
        "  if not o_col: break\n",
        "  # treating outliers by log transforming all columns with skewness\n",
        "  for c in o_col:\n",
        "      X[c] = np.maximum(np.full(X[c].shape, eps), np.minimum(np.full(X[c].shape, 1-eps), X[c]))\n",
        "      X[c] = np.log10(X[c])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoAT2_mx58Pm"
      },
      "source": [
        "#### 3.\tSplit the dataset into train and test. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "P4VAWj3HbIJi"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_FcY7sJ51Gx"
      },
      "source": [
        "#### 4.\tConstruct classification model using RandomForest classifier with different hyper-parameters values.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kH14DLojgHzM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e1949a-1862-4493-f395-f90e43ce8153"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=RandomForestClassifier(),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [None, 3, 5],\n",
              "                         'max_features': [None, 'sqrt', 'log2'],\n",
              "                         'min_samples_leaf': [1, 2, 3],\n",
              "                         'min_samples_split': [2, 3, 4],\n",
              "                         'n_estimators': [50, 100, 150]})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param = {'n_estimators'            :[50,100,150],\n",
        "         'criterion'               :['gini','entropy'],\n",
        "         'max_depth'               :[None,3,5],\n",
        "         'min_samples_split'       :[2,3,4],\n",
        "         'min_samples_leaf'        :[1,2,3],\n",
        "         'max_features'            :[None,'sqrt','log2'],\n",
        "         #'max_leaf_nodes'          :[None,2,3],\n",
        "         #'bootstrap'               :[True,False],\n",
        "         \n",
        "         #'min_weight_fraction_leaf':[0,0.1,0.2],\n",
        "         #'min_impurity_decrease'   :[0,0.1,0.2],\n",
        "         #'oob_score'               :[True,False], \n",
        "         #'n_jobs'                  :[None,-1,2],\n",
        "         #'random_state'            :[None,1,2],\n",
        "         #'class_weight'            :[None,'balanced','balanced_subsample'],\n",
        "         #'ccp_alpha'               :[0,0.1,0.2],\n",
        "         #'max_samples'             :[None,100,0.5]\n",
        "         }\n",
        "model = RandomForestClassifier()\n",
        "clf = GridSearchCV(model,param)\n",
        "clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rqro-zd-lJ1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c98834-eb58-46af-b289-d5faf6dc820a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of Best Random Forest Model: \n",
            "criterion: entropy\n",
            "max_depth: None\n",
            "max_features: log2\n",
            "min_samples_leaf: 3\n",
            "min_samples_split: 2\n",
            "n_estimators: 150\n"
          ]
        }
      ],
      "source": [
        "best_rf = clf.best_estimator_\n",
        "print('Parameters of Best Random Forest Model: ')\n",
        "for k,i in clf.best_params_.items():\n",
        "  print('{}: {}'.format(k,i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldf575RNK5oR"
      },
      "source": [
        "##### 5.\tConstruct Bagging classifier models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cXzO4e5mLYkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd19113a-c80e-4af0-9a13-582d9635faba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=BaggingClassifier(),\n",
              "             param_grid={'base_estimator': [None, LogisticRegression(),\n",
              "                                            GaussianNB()],\n",
              "                         'n_estimators': [5, 10, 15]})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# using base_estimator such as {logistic regressor, Naïve Bayes} \n",
        "# and with different values for n_estimators.\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "param = {'base_estimator'          :[None,LogisticRegression(),GaussianNB()],\n",
        "         'n_estimators'            :[5,10,15],\n",
        "         #'max_samples'             :[1.0,100,0.5],\n",
        "         #'max_features'            :[1.0,5,0.5],\n",
        "         #'bootstrap'               :[True,False],\n",
        "         #'bootstrap_features'      :[True,False],\n",
        "         #'oob_score'               :[True,False], \n",
        "         #'n_jobs'                  :[None,-1,2],\n",
        "         #'random_state'            :[None,1,2],\n",
        "         }\n",
        "model = BaggingClassifier()\n",
        "clf = GridSearchCV(model,param)\n",
        "clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ar08uIH7Ucc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed615b0-7371-4604-f41a-8b015ccf6ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters of Best Bagging Classifier Model: \n",
            "base_estimator: LogisticRegression()\n",
            "n_estimators: 10\n"
          ]
        }
      ],
      "source": [
        "best_bag = clf.best_estimator_\n",
        "print('Parameters of Best Bagging Classifier Model: ')\n",
        "for k,i in clf.best_params_.items():\n",
        "  print('{}: {}'.format(k,i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8JYGCj5Q3GC"
      },
      "source": [
        "#### 6.\tCompare the performance of the constructed models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jPeTS81vW25U"
      },
      "outputs": [],
      "source": [
        "y_rf = best_rf.predict(X_test)\n",
        "y_bag = best_bag.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jT0cbFaWS9VK"
      },
      "outputs": [],
      "source": [
        "# compare the results for train and test subsets using accuracy, precision, recall, f1 score. \n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from numpy import mean\n",
        "\n",
        "rf_a = accuracy_score(y_test,y_rf)\n",
        "rf_p, rf_r, rf_f1,_ = precision_recall_fscore_support(y_test,y_rf)\n",
        "rf_scores = [rf_a,mean(rf_p),mean(rf_r),mean(rf_f1)]\n",
        "\n",
        "bag_a = accuracy_score(y_test,y_bag)\n",
        "bag_p, bag_r, bag_f1,_ = precision_recall_fscore_support(y_test,y_bag)\n",
        "bag_scores = [bag_a,mean(bag_p),mean(bag_r),mean(bag_f1)] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xML88bBDSy6K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7fe43282-ed98-4966-a158-356280061bf6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ind = np.arange(len(rf_scores))\n",
        "width = 0.27\n",
        "\n",
        "ax = plt.figure().add_subplot(111)\n",
        "rects1 = ax.bar(ind-(width/2), rf_scores, width, color='g')\n",
        "rects2 = ax.bar(ind+(width/2), bag_scores, width, color='r')\n",
        "\n",
        "ax.set_xticks(ind)\n",
        "ax.set_xticklabels(['Accuracy','Precision','Recall','F1 Score'])\n",
        "ax.legend((rects1[0], rects2[0]), ('Random Forest', 'Bagging'),loc='center')\n",
        "\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        h = rect.get_height()\n",
        "        ax.text(rect.get_x()+rect.get_width()/2., h, '%.2f'%h, ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X7jOMkAATEYB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "715a9569-e00f-47ea-e067-2091c22d6ddb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Also check the values in confusion matrix.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f, axes = plt.subplots(1, 2, figsize=(15, 5), sharey='row')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_rf, labels=best_rf.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_rf.classes_)\n",
        "disp.plot(ax=axes[0])\n",
        "disp.ax_.set_title('Random Forest Classifier')\n",
        "disp.im_.colorbar.remove()\n",
        "disp.ax_.set_xlabel('')\n",
        "disp.ax_.set_ylabel('True')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_bag, labels=best_bag.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_bag.classes_)\n",
        "disp.plot(ax=axes[1])\n",
        "disp.ax_.set_title('Bagging Classifier')\n",
        "disp.ax_.set_xlabel('')\n",
        "disp.ax_.set_ylabel('')\n",
        "\n",
        "f.text(0.5, 0, 'Predicted', ha='left')\n",
        "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AML6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}